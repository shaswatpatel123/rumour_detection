{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d154dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from data_augmentation import *\n",
    "from util_graph import *\n",
    "from util import *\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from pathlib import PurePath\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96e53619",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "213e3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"path\": \"./all-rnr-annotated-threads\",\n",
    "    \"save_path\": os.path.join(\"./\", \"pheme\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0938078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of all the folders in the parent folder.\n",
    "directories = [os.path.join(args[\"path\"], o) for o in os.listdir(args[\"path\"]) if os.path.isdir(os.path.join(args[\"path\"], o))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c9e5048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing ottawashooting event.\n",
      "ottawashooting event contains 470 tweets for rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 470/470 [00:00<00:00, 887.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ottawashooting event contains 420 tweets for non-rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 420/420 [00:00<00:00, 981.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "Currently processing putinmissing event.\n",
      "putinmissing event contains 126 tweets for rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 2669.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "putinmissing event contains 112 tweets for non-rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 2991.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "Currently processing ferguson event.\n",
      "ferguson event contains 284 tweets for rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 284/284 [00:00<00:00, 660.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ferguson event contains 859 tweets for non-rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 859/859 [00:01<00:00, 689.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "Currently processing prince event.\n",
      "prince event contains 229 tweets for rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 229/229 [00:00<00:00, 2529.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prince event contains 4 tweets for non-rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 2509.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "Currently processing ebola event.\n",
      "ebola event contains 14 tweets for rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 827.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebola event contains 0 tweets for non-rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "Currently processing gurlitt event.\n",
      "gurlitt event contains 61 tweets for rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:00<00:00, 4028.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gurlitt event contains 77 tweets for non-rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 77/77 [00:00<00:00, 4311.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "Currently processing charliehebdo event.\n",
      "charliehebdo event contains 458 tweets for rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 458/458 [00:00<00:00, 847.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charliehebdo event contains 1621 tweets for non-rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1621/1621 [00:02<00:00, 721.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "Currently processing germanwings event.\n",
      "germanwings event contains 238 tweets for rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 238/238 [00:00<00:00, 1245.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "germanwings event contains 231 tweets for non-rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 231/231 [00:00<00:00, 1354.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "Currently processing sydneysiege event.\n",
      "sydneysiege event contains 522 tweets for rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 522/522 [00:00<00:00, 833.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sydneysiege event contains 699 tweets for non-rumours label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 699/699 [00:01<00:00, 675.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Traverse through it to get Source Tweet and Reaction Tweet\n",
    "for dir in directories:\n",
    "\n",
    "    topic = PurePath(dir).parts[-1].split('-')[0]\n",
    "    # Traverse through rumour and non-rumour directories\n",
    "    sub_dir = [os.path.join(dir, i) for i in os.listdir(\n",
    "        dir) if os.path.isdir(os.path.join(dir, i))]\n",
    "\n",
    "    event = PurePath(dir).parts[-1].split('-')[0]\n",
    "    print(f\"Currently processing {event} event.\")\n",
    "    # Make directory for this event at the saving path\n",
    "    save_path = os.path.join(args[\"save_path\"])\n",
    "    os.makedirs( os.path.join(args[\"save_path\"], event), exist_ok=True )\n",
    "\n",
    "    label_json = {}\n",
    "    for sdir in sub_dir:\n",
    "        tweets = [os.path.join(sdir, i) for i in os.listdir(\n",
    "            sdir) if os.path.isdir(os.path.join(sdir, i))]\n",
    "        label = PurePath(sdir).parts[-1]\n",
    "\n",
    "        \n",
    "        os.makedirs(os.path.join(save_path, event, label), exist_ok=True)\n",
    "\n",
    "        print(f\"{event} event contains {len(tweets)} tweets for {label} label\")\n",
    "\n",
    "        os.makedirs(os.path.join(save_path, event, label), exist_ok=True)\n",
    "\n",
    "        for t in tqdm(tweets):\n",
    "            id = PurePath(t).parts[-1]\n",
    "\n",
    "            # Source folder\n",
    "            source_path = os.path.join(t, \"source-tweets\", f\"{id}.json\")\n",
    "            featureMatrix = []\n",
    "\n",
    "            with open(source_path, encoding=\"utf8\") as ofile:\n",
    "                source_json = json.load(ofile)\n",
    "                featureMatrix.append(source_json[\"text\"])\n",
    "\n",
    "            # Reaction Folder\n",
    "            reaction_path = os.path.join(t, \"reactions\")\n",
    "            reactions = [os.path.join(reaction_path, i) for i in os.listdir(\n",
    "                reaction_path) if i.split('\\\\')[-1][0] != '.']\n",
    "\n",
    "            for reaction in reactions:\n",
    "                with open(reaction, encoding=\"utf8\") as ofile:\n",
    "                    obj = json.load(ofile)\n",
    "                    featureMatrix.append(obj[\"text\"])\n",
    "\n",
    "            tweetData = {\n",
    "                \"featureMatrix\": featureMatrix,\n",
    "                \"label\": label\n",
    "            }\n",
    "\n",
    "            # Write in the saving path as id.json\n",
    "            with open(os.path.join(save_path, event, label, f\"{id}.json\"), \"w\", encoding=\"utf8\") as ofile:\n",
    "                json.dump(tweetData, ofile, indent=4)\n",
    "\n",
    "    with open(os.path.join(save_path, event, \"labels.json\"), \"w\", encoding=\"utf8\") as ofile:\n",
    "        json.dump(label_json, ofile, indent=4)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08b11ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "ebola\n",
      "Rumour : 14 | Non-rumour : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 11159.30it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "charliehebdo\n",
      "Rumour : 458 | Non-rumour : 1621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 458/458 [00:00<00:00, 28019.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1621/1621 [00:00<00:00, 26480.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "sydneysiege\n",
      "Rumour : 522 | Non-rumour : 699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 522/522 [00:00<00:00, 29005.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 699/699 [00:00<00:00, 25467.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "ottawashooting\n",
      "Rumour : 470 | Non-rumour : 420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 470/470 [00:00<00:00, 30161.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 420/420 [00:00<00:00, 31166.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "prince\n",
      "Rumour : 229 | Non-rumour : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 229/229 [00:00<00:00, 38748.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 7034.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "putinmissing\n",
      "Rumour : 126 | Non-rumour : 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 34498.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 37250.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "gurlitt\n",
      "Rumour : 61 | Non-rumour : 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:00<00:00, 31431.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 77/77 [00:00<00:00, 38775.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "germanwings\n",
      "Rumour : 238 | Non-rumour : 231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 238/238 [00:00<00:00, 30204.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 231/231 [00:00<00:00, 32104.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "ferguson\n",
      "Rumour : 284 | Non-rumour : 859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 284/284 [00:00<00:00, 24474.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 859/859 [00:00<00:00, 26312.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = \"./\"\n",
    "unaugmented_save_path = os.path.join(SAVE_DIR, \"unaugmented\")\n",
    "os.makedirs(unaugmented_save_path, exist_ok=True)\n",
    "for event in os.listdir(os.path.join(SAVE_DIR, \"pheme\")):\n",
    "    print(\"\\n\")\n",
    "    print(\"*\" * 60)\n",
    "    print(event)\n",
    "\n",
    "    graphList = []\n",
    "\n",
    "    rumourLabel = [\n",
    "        os.path.join(SAVE_DIR, \"pheme\", event, \"rumours\", i) for i in os.listdir(os.path.join(SAVE_DIR, \"pheme\", event, \"rumours\"))]\n",
    "    nonrumourLabel = [\n",
    "        os.path.join(SAVE_DIR, \"pheme\", event, \"non-rumours\", i) for i in os.listdir(os.path.join(SAVE_DIR, \"pheme\", event, \"non-rumours\"))]\n",
    "\n",
    "    # print(f\"\\nTrue : {len(trueLabel)} | False : {len(falseLabel)} | Unverified : {len(unverifiedLabel)} tweets\\n\")\n",
    "    print(f\"Rumour : {len(rumourLabel)} | Non-rumour : {len(nonrumourLabel)}\")\n",
    "\n",
    "    for x in [rumourLabel, nonrumourLabel]:\n",
    "        for f in tqdm(x):\n",
    "            with open(f, encoding=\"utf8\") as ofile:\n",
    "                data = json.load(ofile)\n",
    "            data['x'] = '. '.join( data['featureMatrix'] )\n",
    "            graphList.append( data )\n",
    "\n",
    "    # Save the un-augmented graphList to be used as test dataset\n",
    "    os.makedirs(os.path.join(unaugmented_save_path, event), exist_ok=True)\n",
    "    pickle_path = os.path.join(\n",
    "        unaugmented_save_path, event, 'graph_test.pickle')\n",
    "    with open(pickle_path, 'wb') as handle:\n",
    "        pickle.dump(graphList, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    pickle_path = os.path.join(\n",
    "        unaugmented_save_path, event, 'graph.pickle')\n",
    "    with open(pickle_path, 'wb') as handle:\n",
    "        pickle.dump(graphList, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"\\n\")\n",
    "    print(\"*\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4f71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9763dbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmented data\n",
      "\n",
      "\n",
      "\n",
      "************************************************************\n",
      "ebola\n",
      "Rumour : 14 | Non-rumour : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 12726.54it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "charliehebdo\n",
      "Rumour : 458 | Non-rumour : 1621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 458/458 [00:00<00:00, 28842.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1621/1621 [00:00<00:00, 28282.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmenting entire Rumour label tweets 2 and randomly augmenting 247 tweets\n",
      "NUM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                               | 0/458 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'feat_extractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5426/3169428817.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgetAugmentedData2Label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data_augmentation.py\u001b[0m in \u001b[0;36mgetAugmentedData2Label\u001b[0;34m(SAVE_DIR, improved, AUG_PERC)\u001b[0m\n\u001b[1;32m    287\u001b[0m                 f\"\\nAugmenting entire Rumour label tweets {num - 1} and randomly augmenting {rem} tweets\")\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             graphList.extend(dataAugmentation(\n\u001b[0m\u001b[1;32m    290\u001b[0m                 rumourLabel, num - 1, rem, AUG_PERC, improved))\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data_augmentation.py\u001b[0m in \u001b[0;36mdataAugmentation\u001b[0;34m(data_list, num, rem, p_commets_aug, improved)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimproved\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 augmented_data = nlpAugmentation(\n\u001b[0m\u001b[1;32m    136\u001b[0m                     tweet, num, p_commets_aug)\n\u001b[1;32m    137\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feat_extractor' is not defined"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Augmented data\")\n",
    "print()\n",
    "SAVE_DIR=\"./\"\n",
    "getAugmentedData2Label(SAVE_DIR, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Improved Augmented data\")\n",
    "print()\n",
    "SAVE_DIR=\"./\"\n",
    "getAugmentedData2Label(SAVE_DIR, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef810bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3bb928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
